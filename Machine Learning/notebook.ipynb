{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from datetime import datetime\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "X = pd.read_csv(\"../Cleaning/new_clean_data.csv\", index_col=0)\n",
    "\n",
    "X.dropna(axis=0, subset=[\"price\"], inplace=True)\n",
    "y = X[\"price\"]\n",
    "X.drop([\"price\"], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting categorical values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brand', 'model', 'location', 'body_type', 'fuel', 'transmission', 'color']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
    "categorical_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting numeric values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mileage', 'year', 'power', 'engine_size']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = [\n",
    "    cname for cname in X.columns if X[cname].dtype in [\"int64\", \"float64\"]\n",
    "]\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "X[\"age\"] = now.year - X[\"year\"] + 1\n",
    "X[\"mileage_over_year\"] = X[\"mileage\"] + X[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value (price, brand):  0.0\n",
      "P-value (price, model):  0.0\n",
      "P-value (price, location):  1.471872348992479e-08\n",
      "P-value (price, body_type):  1.9711353417429463e-15\n",
      "P-value (price, fuel):  0.0\n",
      "P-value (price, transmission):  1.7114094636921104e-217\n",
      "P-value (price, color):  1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "for col in categorical_cols:\n",
    "    csq = chi2_contingency(pd.crosstab(data[\"price\"], data[col]))\n",
    "    print(f\"P-value (price, {col}): \", csq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brand', 'model', 'location', 'body_type', 'fuel', 'transmission', 'color']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical_cols=categorical_cols[:-1]\n",
    "categorical_cols\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into Train, Validation and Test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(\n",
    "    X, y, train_size=0.8, test_size=0.2, random_state=0\n",
    ")\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(\n",
    "    X_train_full, y_train, test_size=0.25, random_state=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep selected columns only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputer for num data\n",
    "numerical_transformer = SimpleImputer(strategy=\"mean\")\n",
    "imputed_num_train = pd.DataFrame(\n",
    "    numerical_transformer.fit_transform(X_train[numerical_cols])\n",
    ")\n",
    "\n",
    "imputed_num_valid = pd.DataFrame(\n",
    "    numerical_transformer.transform(X_valid[numerical_cols])\n",
    ")\n",
    "# imputer for cat data\n",
    "categorical_transformer = SimpleImputer(strategy=\"most_frequent\")\n",
    "imputed_cat_train = pd.DataFrame(\n",
    "    categorical_transformer.fit_transform(X_train[categorical_cols])\n",
    ")\n",
    "\n",
    "imputed_cat_valid = pd.DataFrame(\n",
    "    categorical_transformer.transform(X_valid[categorical_cols])\n",
    ")\n",
    "\n",
    "imputed_num_train.columns = numerical_cols\n",
    "imputed_num_valid.columns = numerical_cols\n",
    "imputed_cat_train.columns = categorical_cols\n",
    "imputed_cat_valid.columns = categorical_cols\n",
    "\n",
    "X_train = pd.concat([imputed_num_train, imputed_cat_train], axis=1)\n",
    "X_valid = pd.concat([imputed_num_valid, imputed_cat_valid], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encode the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "OH_X_train = pd.DataFrame(OH_encoder.fit_transform(X_train[categorical_cols]))\n",
    "OH_X_valid = pd.DataFrame(OH_encoder.transform(X_valid[categorical_cols]))\n",
    "OH_X_train.index = X_train.index\n",
    "OH_X_valid.index = X_valid.index\n",
    "\n",
    "\n",
    "num_X_train = X_train.drop(categorical_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(categorical_cols, axis=1)\n",
    "X_train = pd.concat([num_X_train, OH_X_train], axis=1)\n",
    "X_valid = pd.concat([num_X_valid, OH_X_valid], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7504133999023445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=7)\n",
    "forest_model.fit(X_train, y_train)\n",
    "\n",
    "preds = forest_model.predict(X_valid)\n",
    "print(r2_score(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the random grid to search for best hyperparameters\n",
    "# # First create the base model to tune\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# rf = RandomForestRegressor()\n",
    "# # Random search of parameters, using 3 fold cross validation,\n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 2, verbose=2, random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# rf_random.fit(X_train, y_train)\n",
    "# rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_rf_params = {\n",
    "    \"n_estimators\": 800,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"max_features\": \"auto\",\n",
    "    \"max_depth\": 100,\n",
    "    \"bootstrap\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 288 candidates, totalling 576 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    \"bootstrap\": [True],\n",
    "    \"max_depth\": [80, 90, 100, 110],\n",
    "    \"max_features\": [2, 3],\n",
    "    \"min_samples_leaf\": [1, 2, 3],\n",
    "    \"min_samples_split\": [8, 10, 12],\n",
    "    \"n_estimators\": [400, 600, 800, 1000],\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6053215174839077\n"
     ]
    }
   ],
   "source": [
    "best_cv_param = {\n",
    "    \"bootstrap\": True,\n",
    "    \"max_depth\": 110,\n",
    "    \"max_features\": 3,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 8,\n",
    "    \"n_estimators\": 600,\n",
    "}\n",
    "forest_model = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    min_samples_split=12,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=10,\n",
    "    max_depth=110,\n",
    ")\n",
    "forest_model.fit(X_train, y_train)\n",
    "preds = forest_model.predict(X_valid)\n",
    "print(r2_score(y_valid, preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=5,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=4, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=1000, early_stopping_rounds=5, learning_rate=0.05, n_jobs=4\n",
    ")\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7715243464460869\n"
     ]
    }
   ],
   "source": [
    "predictions = xgb.predict(X_valid)\n",
    "acc = r2_score(y_valid, predictions)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# xgb1 = XGBRegressor()\n",
    "# parameters = {'nthread':[4],\n",
    "#               'objective':['reg:linear'],\n",
    "#               'learning_rate': [.03, 0.05, .07],\n",
    "#               'max_depth': [5, 6, 7],\n",
    "#               'min_child_weight': [4],\n",
    "#               'subsample': [0.7],\n",
    "#               'colsample_bytree': [0.7],\n",
    "#               'n_estimators': [500]}\n",
    "\n",
    "# xgb_grid = GridSearchCV(xgb1,\n",
    "#                         parameters,\n",
    "#                         cv = 2,\n",
    "#                         n_jobs = 5,\n",
    "#                         verbose=True)\n",
    "\n",
    "# xgb_grid.fit(X_train,\n",
    "#          y_train)\n",
    "\n",
    "# print(xgb_grid.best_score_)\n",
    "# print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:55:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=500, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
       "             objective='reg:linear', ...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_param = {\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_child_weight\": 4,\n",
    "    \"n_estimators\": 500,\n",
    "    \"nthread\": 4,\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"silent\": 1,\n",
    "    \"subsample\": 0.7,\n",
    "}\n",
    "xgb = XGBRegressor(\n",
    "    colsample_bytree=0.7,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=5,\n",
    "    min_child_weight=4,\n",
    "    n_estimators=500,\n",
    "    nthread=4,\n",
    "    objective=\"reg:linear\",\n",
    "    subsample=0.7,\n",
    ")\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7775961482481565\n"
     ]
    }
   ],
   "source": [
    "predictions = xgb.predict(X_valid)\n",
    "acc = r2_score(y_valid, predictions)\n",
    "print(acc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"alpha\": [\n",
    "        0.0001,\n",
    "        0.001,\n",
    "        0.01,\n",
    "        0.05,\n",
    "        0.1,\n",
    "        0.2,\n",
    "        0.3,\n",
    "        0.4,\n",
    "        0.5,\n",
    "        0.6,\n",
    "        0.7,\n",
    "        0.8,\n",
    "        0.9,\n",
    "        1.0,\n",
    "        2.0,\n",
    "        3.0,\n",
    "        4.0,\n",
    "        5.0,\n",
    "        6.0,\n",
    "        7.0,\n",
    "        8.0,\n",
    "        9.0,\n",
    "        10.0,\n",
    "        20,\n",
    "        50,\n",
    "        100,\n",
    "        500,\n",
    "        1000,\n",
    "    ]\n",
    "}\n",
    "\n",
    "# initialising Ridge() function\n",
    "ridge = Ridge()\n",
    "# defining cross validation folds as 5\n",
    "folds = 5\n",
    "# Defining GridSearchCV\n",
    "grid_cv_model = GridSearchCV(\n",
    "    estimator=ridge, param_grid=params, cv=folds, return_train_score=True, verbose=1\n",
    ")\n",
    "grid_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_cv_model.best_score_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "params = {\"max_depth\": [1, 2, 3, 5, 10, 15, 16, 17, 20]}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=dt, param_grid=params, cv=3)\n",
    "\n",
    "tree_reg = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "parameters = {\"fit_intercept\": [False], \"normalize\": [False], \"copy_X\": [True, False]}\n",
    "gs = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=parameters,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "lin_reg = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.save_model(\"model.xgb\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
