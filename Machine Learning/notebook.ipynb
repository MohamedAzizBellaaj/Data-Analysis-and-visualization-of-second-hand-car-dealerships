{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from datetime import datetime\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "X = pd.read_csv(\"../Cleaning/new_clean_data.csv\", index_col=0)\n",
    "\n",
    "X.dropna(axis=0, subset=[\"price\"], inplace=True)\n",
    "y = X[\"price\"]\n",
    "X.drop([\"price\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting categorical values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brand', 'model', 'location', 'body_type', 'fuel', 'transmission', 'color']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
    "categorical_cols\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting numeric values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mileage', 'year', 'power', 'engine_size']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = [\n",
    "    cname for cname in X.columns if X[cname].dtype in [\"int64\", \"float64\"]\n",
    "]\n",
    "numerical_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "# X[\"age\"] = now.year - X[\"year\"] + 1\n",
    "# X[\"mileage_over_year\"] = X[\"mileage\"] + X[\"age\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value (price, brand):  0.0\n",
      "P-value (price, model):  0.0\n",
      "P-value (price, location):  1.471872348992479e-08\n",
      "P-value (price, body_type):  1.9711353417429463e-15\n",
      "P-value (price, fuel):  0.0\n",
      "P-value (price, transmission):  1.7114094636921104e-217\n",
      "P-value (price, color):  1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "for col in categorical_cols:\n",
    "    csq = chi2_contingency(pd.crosstab(data[\"price\"], data[col]))\n",
    "    print(f\"P-value (price, {col}): \", csq[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brand', 'model', 'location', 'body_type', 'fuel', 'transmission', 'color']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#'body_type', 'fuel', 'transmission'\n",
    "features=['brand', 'model', 'location', 'color']\n",
    "les={}\n",
    "\n",
    "les = {}\n",
    "\n",
    "for f in features:\n",
    "  les[f] = preprocessing.LabelEncoder()\n",
    "  les[f] = les[f].fit(X[f])\n",
    "  X[f] = les[f].transform(X[f])\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into Train, Validation and Test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(\n",
    "    X, y, train_size=0.8, test_size=0.2, random_state=0\n",
    ")\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(\n",
    "    X_train_full, y_train, test_size=0.25, random_state=0\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep selected columns only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brand', 'model', 'location', 'body_type', 'fuel', 'transmission', 'color']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()\n",
    "categorical_cols\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputer for num data\n",
    "numerical_transformer = SimpleImputer(strategy=\"mean\")\n",
    "imputed_num_train = pd.DataFrame(\n",
    "    numerical_transformer.fit_transform(X_train[numerical_cols])\n",
    ")\n",
    "\n",
    "imputed_num_valid = pd.DataFrame(\n",
    "    numerical_transformer.transform(X_valid[numerical_cols])\n",
    ")\n",
    "\n",
    "imputed_num_test = pd.DataFrame(numerical_transformer.transform(X_test[numerical_cols]))\n",
    "# imputer for cat data\n",
    "categorical_transformer = SimpleImputer(strategy=\"most_frequent\")\n",
    "imputed_cat_train = pd.DataFrame(\n",
    "    categorical_transformer.fit_transform(X_train[categorical_cols])\n",
    ")\n",
    "\n",
    "imputed_cat_valid = pd.DataFrame(\n",
    "    categorical_transformer.transform(X_valid[categorical_cols])\n",
    ")\n",
    "\n",
    "imputed_cat_test = pd.DataFrame(\n",
    "    categorical_transformer.transform(X_test[categorical_cols])\n",
    ")\n",
    "\n",
    "imputed_num_train.columns = numerical_cols\n",
    "imputed_num_valid.columns = numerical_cols\n",
    "imputed_num_test.columns = numerical_cols\n",
    "\n",
    "imputed_cat_train.columns = categorical_cols\n",
    "imputed_cat_valid.columns = categorical_cols\n",
    "imputed_cat_test.columns = categorical_cols\n",
    "\n",
    "X_train = pd.concat([imputed_num_train, imputed_cat_train], axis=1)\n",
    "X_valid = pd.concat([imputed_num_valid, imputed_cat_valid], axis=1)\n",
    "X_test = pd.concat([imputed_num_test, imputed_cat_test], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encode the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "cols=['body_type', 'fuel', 'transmission']\n",
    "OH_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "OH_X_train = pd.DataFrame(OH_encoder.fit_transform(X_train[cols]))\n",
    "OH_X_valid = pd.DataFrame(OH_encoder.transform(X_valid[cols]))\n",
    "OH_X_test = pd.DataFrame(OH_encoder.transform(X_test[cols]))\n",
    "OH_X_train.index = X_train.index\n",
    "OH_X_valid.index = X_valid.index\n",
    "OH_X_test.index = X_test.index\n",
    "\n",
    "num_X_train = X_train.drop(cols, axis=1)\n",
    "num_X_valid = X_valid.drop(cols, axis=1)\n",
    "num_X_test = X_test.drop(cols, axis=1)\n",
    "X_train = pd.concat([num_X_train, OH_X_train], axis=1)\n",
    "X_valid = pd.concat([num_X_valid, OH_X_valid], axis=1)\n",
    "X_test = pd.concat([num_X_test, OH_X_test], axis=1)\n",
    "joblib.dump(OH_encoder, 'encoder.pkl')\n",
    "for f in features: \n",
    "    X_train[f] = X_train[f].astype(np.int0)\n",
    "    X_valid[f] = X_valid[f].astype(np.int0)\n",
    "    X_test[f] = X_test[f].astype(np.int0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7472104305401357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=7)\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_valid.columns = X_valid.columns.astype(str)\n",
    "forest_model.fit(X_train, y_train)\n",
    "\n",
    "preds = forest_model.predict(X_valid)\n",
    "print(r2_score(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"bootstrap\": bootstrap,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azizb\\anaconda3\\envs\\qt\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 2000,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 50,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation,\n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=10,\n",
    "    cv=2,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_rf_params = {\n",
    "    \"n_estimators\": 800,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"max_features\": \"auto\",\n",
    "    \"max_depth\": 100,\n",
    "    \"bootstrap\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 288 candidates, totalling 576 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 110,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 800}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    \"bootstrap\": [True],\n",
    "    \"max_depth\": [80, 90, 100, 110],\n",
    "    \"max_features\": [2, 3],\n",
    "    \"min_samples_leaf\": [1, 2, 3],\n",
    "    \"min_samples_split\": [8, 10, 12],\n",
    "    \"n_estimators\": [400, 600, 800, 1000],\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5906640225201317\n"
     ]
    }
   ],
   "source": [
    "best_cv_param = {\n",
    "    \"bootstrap\": True,\n",
    "    \"max_depth\": 100,\n",
    "    \"max_features\": 3,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 8,\n",
    "    \"n_estimators\": 600,\n",
    "}\n",
    "forest_model = RandomForestRegressor(\n",
    "    n_estimators=600,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=3,\n",
    "    max_depth=100,\n",
    "    bootstrap= True,\n",
    ")\n",
    "forest_model.fit(X_train, y_train)\n",
    "preds = forest_model.predict(X_valid)\n",
    "print(r2_score(y_valid, preds))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=5,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=4, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=1000, early_stopping_rounds=5, learning_rate=0.05, n_jobs=4\n",
    ")\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785310980337202\n"
     ]
    }
   ],
   "source": [
    "predictions = xgb.predict(X_valid)\n",
    "acc = r2_score(y_valid, predictions)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n",
      "[13:42:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.771551446896157\n",
      "{'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "xgb1 = XGBRegressor()\n",
    "parameters = {\n",
    "    \"nthread\": [4],\n",
    "    \"objective\": [\"reg:linear\"],\n",
    "    \"learning_rate\": [0.03, 0.05, 0.07],\n",
    "    \"max_depth\": [5, 6, 7],\n",
    "    \"min_child_weight\": [4],\n",
    "    \"subsample\": [0.7],\n",
    "    \"colsample_bytree\": [0.7],\n",
    "    \"n_estimators\": [500],\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1, parameters, cv=2, n_jobs=5, verbose=True)\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=500, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
       "             objective='reg:linear', ...)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_param = {\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_child_weight\": 4,\n",
    "    \"n_estimators\": 500,\n",
    "    \"nthread\": 4,\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"silent\": 1,\n",
    "    \"subsample\": 0.7,\n",
    "}\n",
    "xgb = XGBRegressor(\n",
    "    colsample_bytree=0.7,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=5,\n",
    "    min_child_weight=4,\n",
    "    n_estimators=500,\n",
    "    nthread=4,\n",
    "    objective=\"reg:linear\",\n",
    "    subsample=0.7,\n",
    ")\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7825085265045226\n"
     ]
    }
   ],
   "source": [
    "predictions = xgb.predict(X_valid)\n",
    "acc = r2_score(y_valid, predictions)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.87727e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.08242e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.81142e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.18292e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.03989e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.87727e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.08241e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.81141e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.18292e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.03987e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3,\n",
       "                                   0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0,\n",
       "                                   4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50,\n",
       "                                   100, 500, 1000]},\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"alpha\": [\n",
    "        0.0001,\n",
    "        0.001,\n",
    "        0.01,\n",
    "        0.05,\n",
    "        0.1,\n",
    "        0.2,\n",
    "        0.3,\n",
    "        0.4,\n",
    "        0.5,\n",
    "        0.6,\n",
    "        0.7,\n",
    "        0.8,\n",
    "        0.9,\n",
    "        1.0,\n",
    "        2.0,\n",
    "        3.0,\n",
    "        4.0,\n",
    "        5.0,\n",
    "        6.0,\n",
    "        7.0,\n",
    "        8.0,\n",
    "        9.0,\n",
    "        10.0,\n",
    "        20,\n",
    "        50,\n",
    "        100,\n",
    "        500,\n",
    "        1000,\n",
    "    ]\n",
    "}\n",
    "\n",
    "ridge = Ridge()\n",
    "folds = 5\n",
    "grid_cv_model = GridSearchCV(\n",
    "    estimator=ridge, param_grid=params, cv=folds, return_train_score=True, verbose=1\n",
    ")\n",
    "grid_cv_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5466226344614254\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv_model.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "params = {\"max_depth\": [1, 2, 3, 5, 10, 15, 16, 17, 20]}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=dt, param_grid=params, cv=3)\n",
    "\n",
    "tree_reg = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6659878767468596"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "grid.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "parameters = {\"fit_intercept\": [False], \"copy_X\": [True, False]}\n",
    "gs = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=parameters,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "lin_reg = gs.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5857984294.440003"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost is the most performant of these models so we will use it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7872309885789903\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=1000, early_stopping_rounds=5, learning_rate=0.05, n_jobs=4\n",
    ")\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "predictions = xgb.predict(X_test)\n",
    "acc = r2_score(y_test, predictions)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.save_model(\"model.xgb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
